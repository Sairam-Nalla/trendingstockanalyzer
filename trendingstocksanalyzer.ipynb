{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a95394b-e2d4-41df-8f92-13335eb5bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import time\n",
    "import os\n",
    "import praw\n",
    "import re\n",
    "import datetime\n",
    "import prawcore\n",
    "import tweepy\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import prawcore.exceptions as pc_exc\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import snscrape.base as sb_exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21988c-c38d-433d-85c3-966354452139",
   "metadata": {},
   "source": [
    "# Yahoo Finance Trending Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2ea686-8b97-407b-bde3-cf3f2641b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/137.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def filter_to_equities(symbols):\n",
    "    equities = []\n",
    "    for sym in symbols:\n",
    "        if not re.match(r'^[A-Za-z0-9]+$', sym):\n",
    "           continue\n",
    "        info = yf.Ticker(sym).info\n",
    "        if info.get(\"quoteType\") == \"EQUITY\":\n",
    "            equities.append(sym)\n",
    "    return equities\n",
    "\n",
    "def fetch_trending_symbols(count=10):\n",
    "    \n",
    "    \"\"\"Step 1: get just the tickers that are trending\"\"\"\n",
    "    url = \"https://query1.finance.yahoo.com/v1/finance/trending/US\"\n",
    "    params = {\n",
    "        \"lang\": \"en-US\",\n",
    "        \"region\": \"US\",\n",
    "        \"count\": count,\n",
    "        \"corsDomain\": \"finance.yahoo.com\",\n",
    "    }\n",
    "    resp = requests.get(url, headers=HEADERS, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    # drill into the list of quotes, each quote only has 'symbol'\n",
    "    symbols = [q[\"symbol\"] for q in data[\"finance\"][\"result\"][0][\"quotes\"]]\n",
    "    result = filter_to_equities(symbols)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2caf3bd-a2e5-482d-a0f2-5e2aa7d84d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_top_equities(n, initial_batch=20, max_batch=200, backoff=1.0):\n",
    "    \"\"\"\n",
    "    Return exactly `n` trending equities by:\n",
    "      1) fetching an increasing batch of symbols,\n",
    "      2) filtering to quoteType == \"EQUITY\",\n",
    "      3) stopping once you have `n` (or raising if max_batch is exceeded).\n",
    "    \"\"\"\n",
    "    batch_size = initial_batch\n",
    "    equities = []\n",
    "\n",
    "    while True:\n",
    "        symbols = fetch_trending_symbols(batch_size)\n",
    "        equities = []\n",
    "        for sym in symbols:\n",
    "            info = yf.Ticker(sym).info\n",
    "            if info.get(\"quoteType\") == \"EQUITY\":\n",
    "                equities.append({\n",
    "                    \"ticker\":     sym,\n",
    "                    \"name\":       info.get(\"shortName\"),\n",
    "                    \"price\":      info.get(\"regularMarketPrice\"),\n",
    "                    \"change_pct\": info.get(\"regularMarketChangePercent\"),\n",
    "                })\n",
    "                if len(equities) >= n:\n",
    "                    break\n",
    "\n",
    "        if len(equities) >= n:\n",
    "            # Got enough equities!\n",
    "            return pd.DataFrame(equities[:n])\n",
    "\n",
    "        # Not enough yet: increase batch and retry (with optional delay)\n",
    "        if batch_size >= max_batch:\n",
    "            raise RuntimeError(\n",
    "                f\"Only found {len(equities)} equities in top {batch_size} trending; \"\n",
    "                f\"max_batch ({max_batch}) reached.\"\n",
    "            )\n",
    "        batch_size = min(batch_size * 2, max_batch)\n",
    "        time.sleep(backoff)   # polite pause before re-requesting\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d77a8b9-6342-488d-8c8c-4ead5507c7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker                             name      price  change_pct\n",
      "0    LCID                Lucid Group, Inc.     3.1150   36.026203\n",
      "1     AMC  AMC Entertainment Holdings, Inc     3.5150   10.534593\n",
      "2     PEP                    Pepsico, Inc.   145.4956    7.495825\n",
      "3     NIO                         NIO Inc.     4.4050    7.177617\n",
      "4    RIVN          Rivian Automotive, Inc.    12.9500    4.519770\n",
      "5    BBAI                 BigBear.ai, Inc.     8.0350   12.851124\n",
      "6      QS         QuantumScape Corporation    13.3450   17.577091\n",
      "7    PLTR       Palantir Technologies Inc.   154.1050    2.117151\n",
      "8     ABT              Abbott Laboratories   121.3900   -7.856388\n",
      "9    NVDA               NVIDIA Corporation   173.3550    1.158313\n",
      "10    TSM  Taiwan Semiconductor Manufactur   247.7550    4.291551\n",
      "11   NFLX                    Netflix, Inc.  1271.9950    1.734365\n",
      "12    PGY         Pagaya Technologies Ltd.    29.6800   26.136843\n",
      "13   MSFT            Microsoft Corporation   512.2650    1.314232\n",
      "14    LLY            Eli Lilly and Company   761.8057   -3.544475\n",
      "15    ELV            Elevance Health, Inc.   300.4300  -12.805107\n",
      "16   VLCN                     Volcon, Inc.    21.9000  137.416380\n",
      "17   CRWV                  CoreWeave, Inc.   133.9184   -6.376956\n",
      "18   QBTS              D-Wave Quantum Inc.    19.1450   13.217035\n",
      "19   BTOG               Bit Origin Limited     0.6170   85.955380\n",
      "Results took: 25.980203399900347\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "df_equities = fetch_top_equities(20, initial_batch=20, max_batch=200)\n",
    "print(df_equities)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Results took: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538fa06-be32-4b71-8095-66b9757be136",
   "metadata": {},
   "source": [
    "# Social Media Sentement Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e35757c-10c8-4cf0-a25d-025e4e4d90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#praw -> Python Reddit API Wrapper\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.environ[\"REDDIT_CLIENT_ID\"],\n",
    "    client_secret=os.environ[\"REDDIT_CLIENT_SECRET\"],\n",
    "    user_agent=os.environ[\"REDDIT_USER_AGENT\"],\n",
    ")\n",
    "\n",
    "#tweepy -> twitter api\n",
    "twitter_client = tweepy.Client(bearer_token=os.environ[\"TWITTER_BEARER_TOKEN\"])\n",
    "\n",
    "# Expanded keyword lists for sentiment detection\n",
    "\n",
    "BULLISH_KEYWORDS = [\n",
    "    # Actions / Verbs\n",
    "    \"buy\", \"buying\", \"bought\", \"accumulate\", \"loading up\",\n",
    "    # Slang & Slogans\n",
    "    \"long\", \"diamond hands\", \"ðŸ’ŽðŸ™Œ\", \"rocket\", \"ðŸš€\",\n",
    "    \"to the moon\", \"moon\", \"moonshot\", \"rip\", \"pump\",\n",
    "    # Adjectives & Calls\n",
    "    \"bull\", \"bullish\", \"green\", \"green days\", \"breakout\", \"squeeze\",\n",
    "    # FOMO & Fear-of-Missing-Out\n",
    "    \"fomo\", \"canâ€™t miss\", \"cant miss\", \"donâ€™t sleep on\", \"dont sleep on\"\n",
    "]\n",
    "\n",
    "BEARISH_KEYWORDS = [\n",
    "    # Actions / Verbs\n",
    "    \"sell\", \"selling\", \"sold\", \"dump\", \"dumping\", \"liquidate\", \"offload\", \"plummet\",\n",
    "    # Slang & Slogans\n",
    "    \"short\", \"shorted\", \"short squeeze\", \"paper hands\",\n",
    "    # Adjectives & Warnings\n",
    "    \"bear\", \"bearish\", \"red\", \"crash\", \"crashing\", \"plunge\", \"bleed\", \"weak\",\n",
    "    # Financial Distress\n",
    "    \"bankrupt\", \"margin call\", \"stop loss\", \"capitulation\", \"bagholder\",\n",
    "    # Emojis\n",
    "    \"ðŸ“‰\", \"ðŸ”»\", \"ðŸ˜±\", \"ðŸ˜¢\", \"ðŸ’€\"\n",
    "]\n",
    "STOCK_SUBREDDITS = [\n",
    "    \"stocks\",\n",
    "    \"investing\",\n",
    "    \"StockMarket\",\n",
    "    \"wallstreetbets\",\n",
    "    \"pennystocks\",\n",
    "    \"robinhood\"\n",
    "]\n",
    "ALL_SUBS = \"+\".join(STOCK_SUBREDDITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95049a0-4740-4116-be10-fda64567ece1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # def detect_sentiment(text):\n",
    "# #     t = text.lower()\n",
    "# #     bullish = any(k in t for k in BULLISH_KEYWORDS)\n",
    "# #     bearish = any(k in t for k in BEARISH_KEYWORDS)\n",
    "# #     return bullish, bearish\n",
    "\n",
    "# def fetch_reddit_stock_sentiment(ticker, total_limit=500, max_comments=20):\n",
    "#     \"\"\"\n",
    "#     Fetch up to 30 days back total_limit posts for $TICKER across STOCK_SUBREDDITS,\n",
    "#     include up to max_comments per post, and flag bullish/bearish.\n",
    "#     Returns agg_dict.\n",
    "#     \"\"\"\n",
    "#     # 30 days in sec\n",
    "#     cutoff = (time.time() - 30 * 24 * 3600)\n",
    "#     query = f\"${ticker} lang:en\"\n",
    "#     records = []\n",
    "#     comment_count = 0\n",
    "#     bullish_count = 0\n",
    "#     bearish_count = 0\n",
    "\n",
    "#     clean = \"\".join(ch for ch in ticker if ch.isalnum()).upper()\n",
    "#     # match either with or without the $ prefix\n",
    "#     query = f'\"${clean}\" OR \"{clean}\"'\n",
    "#     for post in reddit.subreddit(ALL_SUBS).search(query,\n",
    "#                                                  limit=total_limit,\n",
    "#                                                  sort=\"new\"):\n",
    "#         # grab post text\n",
    "#         if post.created_utc > cutoff:\n",
    "#             break        # all remaining posts will be older\n",
    "        \n",
    "#         pieces = [post.title or \"\", post.selftext or \"\"]\n",
    "        \n",
    "#         # grab comments (up to max_comments)\n",
    "#         post.comments.replace_more(limit=0)\n",
    "#         flat_comments = post.comments.list()[:max_comments]\n",
    "#         pieces += [c.body for c in flat_comments]\n",
    "        \n",
    "#         full_text = \" \".join(pieces)\n",
    "#         # is_bullish, is_bearish = detect_sentiment(full_text)\n",
    "\n",
    "#         for c in flat_comments:\n",
    "#             text = c.body.lower()\n",
    "#             # print(text)\n",
    "#             comment_count += 1\n",
    "#             if any(k in text for k in BULLISH_KEYWORDS):\n",
    "#                 bullish_count += 1\n",
    "#             if any(k in text for k in BEARISH_KEYWORDS):\n",
    "#                 bearish_count += 1\n",
    "        \n",
    "#             # print(\"bullish: \" + str(bullish_count))\n",
    "#             # print(\"bearish: \" + str(bearish_count))\n",
    "        \n",
    "#         # print(full_text)\n",
    "#         records.append({\n",
    "#             \"ticker\":      ticker,\n",
    "#             \"subreddit\":   post.subreddit.display_name,\n",
    "#             \"created_utc\": datetime.datetime.utcfromtimestamp(post.created_utc),\n",
    "#             \"bullish\":     bullish_count,\n",
    "#             \"bearish\":     bearish_count,\n",
    "#             # optional for debugging:\n",
    "#             # \"raw_text\": full_text[:200]  \n",
    "#         })\n",
    "#     df = pd.DataFrame(records)\n",
    "#     # display(df)\n",
    "#     # build your aggregate metrics\n",
    "#     agg = {\n",
    "#         \"ticker\": ticker,\n",
    "#         \"reddit_mentions\": len(df),\n",
    "#         \"reddit_bullish\":  int(df[\"bullish\"].sum()) if not df.empty else 0,\n",
    "#         \"reddit_bearish\":  int(df[\"bearish\"].sum()) if not df.empty else 0,\n",
    "#     }\n",
    "#     return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0254365c-0665-4f66-95c0-9494aa4267e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def fetch_reddit_sentiment_for_all_equities(\n",
    "#     df_equities,\n",
    "#     total_limit=200,\n",
    "#     max_comments=50\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     For each ticker in df_equities['ticker'], call\n",
    "#     fetch_reddit_comment_sentiment() to get:\n",
    "#       - reddit_comment_count\n",
    "#       - reddit_comment_bullish\n",
    "#       - reddit_comment_bearish\n",
    "\n",
    "#     Then rename those last two to bullish_count/bearish_count\n",
    "#     and merge them back into df_equities.\n",
    "#     \"\"\"\n",
    "#     # 1) Gather all metrics into a list of dicts\n",
    "#     records = []\n",
    "#     for ticker in df_equities['ticker']:\n",
    "#         try:\n",
    "#             result = fetch_reddit_stock_sentiment(ticker)\n",
    "#         except Exception:\n",
    "#             print(Exception)\n",
    "#             result = {\n",
    "#                 \"reddit_comment_count\":   0,\n",
    "#                 \"reddit_com ment_bullish\": 0,\n",
    "#                 \"reddit_comment_bearish\": 0,\n",
    "#             }\n",
    "#         records.append(result)\n",
    "    \n",
    "#     # 2) Build a DataFrame of raw metrics\n",
    "#     df_metrics = pd.DataFrame(records)\n",
    "#     display(df_metrics)\n",
    "    \n",
    "#     # 3) Merge by direct assignment (avoids any KeyError on slicing)\n",
    "#     df = df_equities.reset_index(drop=True).copy()\n",
    "#     df[\"reddit_bullish_count\"] = df_metrics[\"reddit_bullish\"]\n",
    "#     df[\"reddit_bearish_count\"] = df_metrics[\"reddit_bearish\"]\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Usage:\n",
    "\n",
    "# # print(df_equities)\n",
    "# df_with_reddit = fetch_reddit_sentiment_for_all_equities(df_equities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f1ad8-dcfe-4da6-821e-5d0928422ade",
   "metadata": {},
   "source": [
    "# Reddit Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605c54ae-ac17-4ab0-b77a-78bfb4fc71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_metrics_for_reddit(ticker):\n",
    "    full_empty ={\n",
    "        \"ticker\":                      ticker,\n",
    "        \"reddit_post_count\":           0,\n",
    "        \"reddit_post_bullish\":         0,\n",
    "        \"reddit_post_bearish\":         0,\n",
    "        \"reddit_comment_count\":        0,\n",
    "        \"reddit_comment_bullish\":      0,\n",
    "        \"reddit_comment_bearish\":      0,\n",
    "        \"reddit_weighted_comment_bull\":0,\n",
    "        \"reddit_weighted_comment_bear\":0,\n",
    "        \"reddit_avg_comment_sentiment\":0.0,\n",
    "        \"reddit_bullish_ratio\":        0.0,\n",
    "        \"reddit_bearish_ratio\":        0.0,\n",
    "    }\n",
    "    partial_empty = {\n",
    "        \"ticker\": ticker,\n",
    "        \"reddit_avg_comment_sentiment\": 0,\n",
    "        \"reddit_bullish_ratio\": 0,\n",
    "        \"reddit_bearish_ratio\": 0\n",
    "    }\n",
    "\n",
    "    return full_empty, partial_empty\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd98d09d-dfa2-4a6b-a5ae-d8e5a7ad8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def fetch_reddit_stock_sentiment(ticker: str,\n",
    "                                 company_name: str,\n",
    "                                 total_limit: int = 500,\n",
    "                                 max_comments: int = 20):\n",
    "    \"\"\"\n",
    "    Fetch sentiment signals for $TICKER over the past 30 days.\n",
    "    Returns a metrics dict with:\n",
    "      - reddit_post_count\n",
    "      - reddit_post_bullish\n",
    "      - reddit_post_bearish\n",
    "      - reddit_comment_count\n",
    "      - reddit_comment_bullish\n",
    "      - reddit_comment_bearish\n",
    "      - reddit_weighted_comment_bullish\n",
    "      - reddit_weighted_comment_bearish\n",
    "      - reddit_avg_comment_sentiment\n",
    "    \"\"\"\n",
    "    # 1) 30-day cutoff\n",
    "    now = time.time()\n",
    "    cutoff = now - 30 * 24 * 3600\n",
    "\n",
    "    # 2) Build a query matching either $TICKER or plain TICKER\n",
    "    clean_tkr = \"\".join(ch for ch in ticker if ch.isalnum()).upper()\n",
    "    clean_nm  = \"\".join(ch for ch in company_name if ch.isalnum() or ch.isspace()).upper()\n",
    "    # match cashtag, bare ticker, **or** company name\n",
    "    query = f'\"${clean_tkr}\" OR \"{clean_tkr}\" OR \"{clean_nm}\"'\n",
    "\n",
    "\n",
    "    # 3) Initialize counters\n",
    "    post_count = comment_count = 0\n",
    "    post_bull = post_bear = 0\n",
    "    comment_bull = comment_bear = 0\n",
    "    weighted_comment_bull = weighted_comment_bear = 0\n",
    "    total_compound = 0.0\n",
    "\n",
    "    try:\n",
    "        for post in reddit.subreddit(ALL_SUBS).search(\n",
    "            query, limit=total_limit, sort=\"new\"\n",
    "        ):\n",
    "            # stop once posts fall outside our 30-day window\n",
    "            if post.created_utc < cutoff:\n",
    "                break\n",
    "            post_count += 1\n",
    "\n",
    "            # 4) Post-level sentiment\n",
    "            post_text = (post.title + \" \" + getattr(post, \"selftext\", \"\")).lower()\n",
    "            if any(k in post_text for k in BULLISH_KEYWORDS):\n",
    "                post_bull += 1\n",
    "            if any(k in post_text for k in BEARISH_KEYWORDS):\n",
    "                post_bear += 1\n",
    "\n",
    "            # 5) Gather comments\n",
    "            post.comments.replace_more(limit=0)\n",
    "            comments = post.comments.list()[:max_comments]\n",
    "            for c in comments:\n",
    "                # skip old comments\n",
    "                if c.created_utc < cutoff:\n",
    "                    continue\n",
    "\n",
    "                comment_count += 1\n",
    "                txt = c.body\n",
    "                low = txt.lower()\n",
    "                is_bull = any(k in low for k in BULLISH_KEYWORDS)\n",
    "                is_bear = any(k in low for k in BEARISH_KEYWORDS)\n",
    "\n",
    "                # simple counts\n",
    "                comment_bull += int(is_bull)\n",
    "                comment_bear += int(is_bear)\n",
    "\n",
    "                # weight by post upvotes (as a proxy for visibility)\n",
    "                score = getattr(c, \"score\", 0)\n",
    "                weighted_comment_bull += score if is_bull else 0\n",
    "                weighted_comment_bear += score if is_bear else 0\n",
    "\n",
    "                # VADER compound score\n",
    "                total_compound += sia.polarity_scores(txt)[\"compound\"]\n",
    "\n",
    "    except prawcore.exceptions.BadRequest:\n",
    "        # existing BadRequest handlerâ€¦\n",
    "        return zero_metrics_for_reddit(ticker)\n",
    "    except pc_exc.ServerError as e:\n",
    "        print(f\"âš ï¸ Reddit server error for {ticker}: {e}\")\n",
    "        return zero_metrics_for_reddit(ticker)\n",
    "\n",
    "    # 6) Final derived metrics\n",
    "    avg_compound = total_compound / comment_count if comment_count else 0.0\n",
    "    bullish_ratio = (post_bull+comment_bull)/(post_count+comment_count) if comment_count else 0.0\n",
    "    bearish_ratio = (post_bear+comment_bear)/(post_count+comment_count) if comment_count else 0.0\n",
    "    \n",
    "    \n",
    "    full_reddit_df = {\n",
    "        \"ticker\": ticker,\n",
    "        \"reddit_post_count\": post_count,\n",
    "        \"reddit_post_bullish\": post_bull,\n",
    "        \"reddit_post_bearish\": post_bear,\n",
    "        \"reddit_comment_count\": comment_count,\n",
    "        \"reddit_comment_bullish\": comment_bull,\n",
    "        \"reddit_comment_bearish\": comment_bear,\n",
    "        \"reddit_weighted_comment_bullish\": weighted_comment_bull,\n",
    "        \"reddit_weighted_comment_bearish\": weighted_comment_bear,\n",
    "        \"reddit_avg_comment_sentiment\": round(avg_compound, 4),\n",
    "        \"reddit_bullish_ratio\": round(bullish_ratio, 4),\n",
    "        \"reddit_bearish_ratio\": round(bearish_ratio, 4)\n",
    "    }\n",
    "\n",
    "    reddit_sentiment_df = {\n",
    "        \"ticker\": ticker,\n",
    "        \"reddit_avg_comment_sentiment\": round(avg_compound, 4),\n",
    "        \"reddit_bullish_ratio\": round(bullish_ratio, 4),\n",
    "        \"reddit_bearish_ratio\": round(bearish_ratio, 4)\n",
    "    }\n",
    "\n",
    "    return full_reddit_df, reddit_sentiment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ff5b13-cdaf-4f58-886d-72fe28ffb4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_reddit(df):\n",
    "    df_copy = df.copy()\n",
    "    records = []\n",
    "    full_records = []\n",
    "    for ticker, name in zip(df[\"ticker\"], df[\"name\"]):\n",
    "        full_metrics, sentiment_metrics = fetch_reddit_stock_sentiment(\n",
    "            ticker,\n",
    "            company_name=name,\n",
    "            total_limit=500,\n",
    "            max_comments=20\n",
    "        )\n",
    "        records.append(sentiment_metrics)\n",
    "        full_records.append(full_metrics)\n",
    "\n",
    "    df_full = pd.DataFrame(full_records).set_index(\"ticker\")\n",
    "    df_full_reddit_metrics = df_copy.join(df_full, on=\"ticker\", how=\"left\")\n",
    "    \n",
    "    df_metrics = pd.DataFrame(records).set_index(\"ticker\")\n",
    "    df_sentiment_metrics = df.join(df_metrics, on=\"ticker\", how=\"left\")\n",
    "    \n",
    "    return df_full_reddit_metrics, df_sentiment_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b620d3-1982-4502-ae42-b37b0a99b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results took: 202.2235278999433\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "df_full_reddit, df_sentiment_reddit = merge_reddit(df_equities)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Results took: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775c8f43-4cda-4c91-a11b-340ee094ecc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>change_pct</th>\n",
       "      <th>reddit_post_count</th>\n",
       "      <th>reddit_post_bullish</th>\n",
       "      <th>reddit_post_bearish</th>\n",
       "      <th>reddit_comment_count</th>\n",
       "      <th>reddit_comment_bullish</th>\n",
       "      <th>reddit_comment_bearish</th>\n",
       "      <th>reddit_weighted_comment_bullish</th>\n",
       "      <th>reddit_weighted_comment_bearish</th>\n",
       "      <th>reddit_avg_comment_sentiment</th>\n",
       "      <th>reddit_bullish_ratio</th>\n",
       "      <th>reddit_bearish_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCID</td>\n",
       "      <td>Lucid Group, Inc.</td>\n",
       "      <td>3.1150</td>\n",
       "      <td>36.026203</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>443</td>\n",
       "      <td>607</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMC</td>\n",
       "      <td>AMC Entertainment Holdings, Inc</td>\n",
       "      <td>3.5150</td>\n",
       "      <td>10.534593</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>Pepsico, Inc.</td>\n",
       "      <td>145.4956</td>\n",
       "      <td>7.495825</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>478</td>\n",
       "      <td>379</td>\n",
       "      <td>-0.0197</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO Inc.</td>\n",
       "      <td>4.4050</td>\n",
       "      <td>7.177617</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>284</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIVN</td>\n",
       "      <td>Rivian Automotive, Inc.</td>\n",
       "      <td>12.9500</td>\n",
       "      <td>4.519770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BBAI</td>\n",
       "      <td>BigBear.ai, Inc.</td>\n",
       "      <td>8.0350</td>\n",
       "      <td>12.851124</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>299</td>\n",
       "      <td>389</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QS</td>\n",
       "      <td>QuantumScape Corporation</td>\n",
       "      <td>13.3450</td>\n",
       "      <td>17.577091</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>566</td>\n",
       "      <td>183</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>Palantir Technologies Inc.</td>\n",
       "      <td>154.1050</td>\n",
       "      <td>2.117151</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>816</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>3594</td>\n",
       "      <td>3666</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>-7.856388</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>488</td>\n",
       "      <td>357</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "      <td>173.3550</td>\n",
       "      <td>1.158313</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>2109</td>\n",
       "      <td>426</td>\n",
       "      <td>445</td>\n",
       "      <td>24928</td>\n",
       "      <td>23864</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TSM</td>\n",
       "      <td>Taiwan Semiconductor Manufactur</td>\n",
       "      <td>247.7550</td>\n",
       "      <td>4.291551</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>312</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>1271.9950</td>\n",
       "      <td>1.734365</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>711</td>\n",
       "      <td>432</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PGY</td>\n",
       "      <td>Pagaya Technologies Ltd.</td>\n",
       "      <td>29.6800</td>\n",
       "      <td>26.136843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>512.2650</td>\n",
       "      <td>1.314232</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>522</td>\n",
       "      <td>107</td>\n",
       "      <td>113</td>\n",
       "      <td>1652</td>\n",
       "      <td>2032</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LLY</td>\n",
       "      <td>Eli Lilly and Company</td>\n",
       "      <td>761.8057</td>\n",
       "      <td>-3.544475</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>154</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ELV</td>\n",
       "      <td>Elevance Health, Inc.</td>\n",
       "      <td>300.4300</td>\n",
       "      <td>-12.805107</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>394</td>\n",
       "      <td>205</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VLCN</td>\n",
       "      <td>Volcon, Inc.</td>\n",
       "      <td>21.9000</td>\n",
       "      <td>137.416380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRWV</td>\n",
       "      <td>CoreWeave, Inc.</td>\n",
       "      <td>133.9184</td>\n",
       "      <td>-6.376956</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>276</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>1363</td>\n",
       "      <td>492</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QBTS</td>\n",
       "      <td>D-Wave Quantum Inc.</td>\n",
       "      <td>19.1450</td>\n",
       "      <td>13.217035</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BTOG</td>\n",
       "      <td>Bit Origin Limited</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>85.955380</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.3077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker                             name      price  change_pct  \\\n",
       "0    LCID                Lucid Group, Inc.     3.1150   36.026203   \n",
       "1     AMC  AMC Entertainment Holdings, Inc     3.5150   10.534593   \n",
       "2     PEP                    Pepsico, Inc.   145.4956    7.495825   \n",
       "3     NIO                         NIO Inc.     4.4050    7.177617   \n",
       "4    RIVN          Rivian Automotive, Inc.    12.9500    4.519770   \n",
       "5    BBAI                 BigBear.ai, Inc.     8.0350   12.851124   \n",
       "6      QS         QuantumScape Corporation    13.3450   17.577091   \n",
       "7    PLTR       Palantir Technologies Inc.   154.1050    2.117151   \n",
       "8     ABT              Abbott Laboratories   121.3900   -7.856388   \n",
       "9    NVDA               NVIDIA Corporation   173.3550    1.158313   \n",
       "10    TSM  Taiwan Semiconductor Manufactur   247.7550    4.291551   \n",
       "11   NFLX                    Netflix, Inc.  1271.9950    1.734365   \n",
       "12    PGY         Pagaya Technologies Ltd.    29.6800   26.136843   \n",
       "13   MSFT            Microsoft Corporation   512.2650    1.314232   \n",
       "14    LLY            Eli Lilly and Company   761.8057   -3.544475   \n",
       "15    ELV            Elevance Health, Inc.   300.4300  -12.805107   \n",
       "16   VLCN                     Volcon, Inc.    21.9000  137.416380   \n",
       "17   CRWV                  CoreWeave, Inc.   133.9184   -6.376956   \n",
       "18   QBTS              D-Wave Quantum Inc.    19.1450   13.217035   \n",
       "19   BTOG               Bit Origin Limited     0.6170   85.955380   \n",
       "\n",
       "    reddit_post_count  reddit_post_bullish  reddit_post_bearish  \\\n",
       "0                   4                    3                    2   \n",
       "1                   3                    2                    3   \n",
       "2                   9                    4                    5   \n",
       "3                   6                    5                    3   \n",
       "4                   0                    0                    0   \n",
       "5                   6                    5                    4   \n",
       "6                  10                    7                    4   \n",
       "7                  49                   31                   21   \n",
       "8                  12                    4                    7   \n",
       "9                 135                   80                   76   \n",
       "10                 12                    8                    7   \n",
       "11                 12                    7                    9   \n",
       "12                  0                    0                    0   \n",
       "13                 35                   20                   25   \n",
       "14                 13                    9                   11   \n",
       "15                  9                    5                    5   \n",
       "16                  0                    0                    0   \n",
       "17                 26                   13                    8   \n",
       "18                  3                    2                    3   \n",
       "19                  2                    2                    2   \n",
       "\n",
       "    reddit_comment_count  reddit_comment_bullish  reddit_comment_bearish  \\\n",
       "0                     55                      19                      26   \n",
       "1                     29                       5                       7   \n",
       "2                    114                      16                      20   \n",
       "3                    100                      11                      19   \n",
       "4                      0                       0                       0   \n",
       "5                     97                      15                      30   \n",
       "6                    140                      25                      33   \n",
       "7                    816                     162                     172   \n",
       "8                    113                      19                      19   \n",
       "9                   2109                     426                     445   \n",
       "10                   125                      29                      21   \n",
       "11                   150                      36                      26   \n",
       "12                     0                       0                       0   \n",
       "13                   522                     107                     113   \n",
       "14                   154                      32                      27   \n",
       "15                   102                      15                      16   \n",
       "16                     0                       0                       0   \n",
       "17                   276                      56                      60   \n",
       "18                    46                       9                       6   \n",
       "19                    37                       3                      10   \n",
       "\n",
       "    reddit_weighted_comment_bullish  reddit_weighted_comment_bearish  \\\n",
       "0                               443                              607   \n",
       "1                                 8                               12   \n",
       "2                               478                              379   \n",
       "3                                69                              284   \n",
       "4                                 0                                0   \n",
       "5                               299                              389   \n",
       "6                               566                              183   \n",
       "7                              3594                             3666   \n",
       "8                               488                              357   \n",
       "9                             24928                            23864   \n",
       "10                              312                              211   \n",
       "11                              711                              432   \n",
       "12                                0                                0   \n",
       "13                             1652                             2032   \n",
       "14                              175                              172   \n",
       "15                              394                              205   \n",
       "16                                0                                0   \n",
       "17                             1363                              492   \n",
       "18                               72                             1457   \n",
       "19                                7                               14   \n",
       "\n",
       "    reddit_avg_comment_sentiment  reddit_bullish_ratio  reddit_bearish_ratio  \n",
       "0                         0.1925                0.3729                0.4746  \n",
       "1                         0.3486                0.2188                0.3125  \n",
       "2                        -0.0197                0.1626                0.2033  \n",
       "3                         0.0143                0.1509                0.2075  \n",
       "4                         0.0000                0.0000                0.0000  \n",
       "5                         0.2611                0.1942                0.3301  \n",
       "6                         0.1639                0.2133                0.2467  \n",
       "7                         0.1508                0.2231                0.2231  \n",
       "8                         0.0098                0.1840                0.2080  \n",
       "9                         0.1587                0.2255                0.2322  \n",
       "10                        0.0958                0.2701                0.2044  \n",
       "11                        0.0063                0.2654                0.2160  \n",
       "12                        0.0000                0.0000                0.0000  \n",
       "13                        0.1768                0.2280                0.2478  \n",
       "14                        0.1119                0.2455                0.2275  \n",
       "15                        0.0425                0.1802                0.1892  \n",
       "16                        0.0000                0.0000                0.0000  \n",
       "17                        0.1282                0.2285                0.2252  \n",
       "18                        0.0376                0.2245                0.1837  \n",
       "19                        0.1234                0.1282                0.3077  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_full_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db95c93-fba9-46de-9d49-2e82a620f08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>change_pct</th>\n",
       "      <th>reddit_avg_comment_sentiment</th>\n",
       "      <th>reddit_bullish_ratio</th>\n",
       "      <th>reddit_bearish_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCID</td>\n",
       "      <td>Lucid Group, Inc.</td>\n",
       "      <td>3.1150</td>\n",
       "      <td>36.026203</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMC</td>\n",
       "      <td>AMC Entertainment Holdings, Inc</td>\n",
       "      <td>3.5150</td>\n",
       "      <td>10.534593</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>Pepsico, Inc.</td>\n",
       "      <td>145.4956</td>\n",
       "      <td>7.495825</td>\n",
       "      <td>-0.0197</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO Inc.</td>\n",
       "      <td>4.4050</td>\n",
       "      <td>7.177617</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIVN</td>\n",
       "      <td>Rivian Automotive, Inc.</td>\n",
       "      <td>12.9500</td>\n",
       "      <td>4.519770</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BBAI</td>\n",
       "      <td>BigBear.ai, Inc.</td>\n",
       "      <td>8.0350</td>\n",
       "      <td>12.851124</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QS</td>\n",
       "      <td>QuantumScape Corporation</td>\n",
       "      <td>13.3450</td>\n",
       "      <td>17.577091</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>Palantir Technologies Inc.</td>\n",
       "      <td>154.1050</td>\n",
       "      <td>2.117151</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>-7.856388</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "      <td>173.3550</td>\n",
       "      <td>1.158313</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TSM</td>\n",
       "      <td>Taiwan Semiconductor Manufactur</td>\n",
       "      <td>247.7550</td>\n",
       "      <td>4.291551</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>1271.9950</td>\n",
       "      <td>1.734365</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PGY</td>\n",
       "      <td>Pagaya Technologies Ltd.</td>\n",
       "      <td>29.6800</td>\n",
       "      <td>26.136843</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>512.2650</td>\n",
       "      <td>1.314232</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LLY</td>\n",
       "      <td>Eli Lilly and Company</td>\n",
       "      <td>761.8057</td>\n",
       "      <td>-3.544475</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ELV</td>\n",
       "      <td>Elevance Health, Inc.</td>\n",
       "      <td>300.4300</td>\n",
       "      <td>-12.805107</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VLCN</td>\n",
       "      <td>Volcon, Inc.</td>\n",
       "      <td>21.9000</td>\n",
       "      <td>137.416380</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRWV</td>\n",
       "      <td>CoreWeave, Inc.</td>\n",
       "      <td>133.9184</td>\n",
       "      <td>-6.376956</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QBTS</td>\n",
       "      <td>D-Wave Quantum Inc.</td>\n",
       "      <td>19.1450</td>\n",
       "      <td>13.217035</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BTOG</td>\n",
       "      <td>Bit Origin Limited</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>85.955380</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.3077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker                             name      price  change_pct  \\\n",
       "0    LCID                Lucid Group, Inc.     3.1150   36.026203   \n",
       "1     AMC  AMC Entertainment Holdings, Inc     3.5150   10.534593   \n",
       "2     PEP                    Pepsico, Inc.   145.4956    7.495825   \n",
       "3     NIO                         NIO Inc.     4.4050    7.177617   \n",
       "4    RIVN          Rivian Automotive, Inc.    12.9500    4.519770   \n",
       "5    BBAI                 BigBear.ai, Inc.     8.0350   12.851124   \n",
       "6      QS         QuantumScape Corporation    13.3450   17.577091   \n",
       "7    PLTR       Palantir Technologies Inc.   154.1050    2.117151   \n",
       "8     ABT              Abbott Laboratories   121.3900   -7.856388   \n",
       "9    NVDA               NVIDIA Corporation   173.3550    1.158313   \n",
       "10    TSM  Taiwan Semiconductor Manufactur   247.7550    4.291551   \n",
       "11   NFLX                    Netflix, Inc.  1271.9950    1.734365   \n",
       "12    PGY         Pagaya Technologies Ltd.    29.6800   26.136843   \n",
       "13   MSFT            Microsoft Corporation   512.2650    1.314232   \n",
       "14    LLY            Eli Lilly and Company   761.8057   -3.544475   \n",
       "15    ELV            Elevance Health, Inc.   300.4300  -12.805107   \n",
       "16   VLCN                     Volcon, Inc.    21.9000  137.416380   \n",
       "17   CRWV                  CoreWeave, Inc.   133.9184   -6.376956   \n",
       "18   QBTS              D-Wave Quantum Inc.    19.1450   13.217035   \n",
       "19   BTOG               Bit Origin Limited     0.6170   85.955380   \n",
       "\n",
       "    reddit_avg_comment_sentiment  reddit_bullish_ratio  reddit_bearish_ratio  \n",
       "0                         0.1925                0.3729                0.4746  \n",
       "1                         0.3486                0.2188                0.3125  \n",
       "2                        -0.0197                0.1626                0.2033  \n",
       "3                         0.0143                0.1509                0.2075  \n",
       "4                         0.0000                0.0000                0.0000  \n",
       "5                         0.2611                0.1942                0.3301  \n",
       "6                         0.1639                0.2133                0.2467  \n",
       "7                         0.1508                0.2231                0.2231  \n",
       "8                         0.0098                0.1840                0.2080  \n",
       "9                         0.1587                0.2255                0.2322  \n",
       "10                        0.0958                0.2701                0.2044  \n",
       "11                        0.0063                0.2654                0.2160  \n",
       "12                        0.0000                0.0000                0.0000  \n",
       "13                        0.1768                0.2280                0.2478  \n",
       "14                        0.1119                0.2455                0.2275  \n",
       "15                        0.0425                0.1802                0.1892  \n",
       "16                        0.0000                0.0000                0.0000  \n",
       "17                        0.1282                0.2285                0.2252  \n",
       "18                        0.0376                0.2245                0.1837  \n",
       "19                        0.1234                0.1282                0.3077  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(df_equities)\n",
    "display(df_sentiment_reddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733684ba-04bf-4746-b1b7-32350a55d4e5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6d71e2-350d-4960-a13b-35038c91d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_twitter_stock_sentiment(ticker, company_name=None, max_results=100):\n",
    "#     clean = \"\".join(ch for ch in ticker if ch.isalnum()).upper()\n",
    "#     query_tkr = f'\"${clean}\" OR \"{clean}\"'\n",
    "#     if company_name:\n",
    "#         clean_nm = \"\".join(ch for ch in company_name if ch.isalnum() or ch.isspace())\n",
    "#         query_tkr += f' OR \"{clean_nm}\"'\n",
    "#     query = f\"{query_tkr} lang:en -is:retweet\"\n",
    "\n",
    "#     tweets = twitter_client.search_recent_tweets(query,\n",
    "#                                         tweet_fields=[\"text\", \"public_metrics\"],\n",
    "#                                         max_results=max_results).data or []\n",
    "\n",
    "#     mentions = len(tweets)\n",
    "#     tweets_count = bull = bear = 0\n",
    "#     total_compound = 0.0\n",
    "    \n",
    "\n",
    "#     for t in tweets:\n",
    "#         text = t.text\n",
    "#         low = text.lower()\n",
    "#         is_bull = any(k in low for k in BULLISH_KEYWORDS)\n",
    "#         is_bear = any(k in low for k in BEARISH_KEYWORDS)\n",
    "#         bull += int(is_bull)\n",
    "#         bear += int(is_bear)\n",
    "#         tweets_count += 1\n",
    "#         total_compound += sia.polarity_scores(text)[\"compound\"]\n",
    "    \n",
    "#     avg_compound = total_compound / mentions if mentions else 0.0\n",
    "#     bearish_ratio = bear/tweets_count\n",
    "#     bullish_ratio = bull/tweets_count\n",
    "    \n",
    "#     full_twitter_df = {\n",
    "#         \"ticker\": ticker,\n",
    "#         \"twitter_mentions\": mentions,\n",
    "#         \"twitter_bullish_count\": bull,\n",
    "#         \"twitter_bearish_count\": bear,\n",
    "#         \"twitter_avg_sentiment\": round(avg_compound, 4),\n",
    "#         \"twitter_bullish_ratio\": round(bullish_ratio, 4),\n",
    "#         \"twitter_bearish_ratio\": round(bearish_ratio, 4)\n",
    "#     }\n",
    "\n",
    "#     twitter_sentiment_df = {\n",
    "#         \"ticker\": ticker,\n",
    "#         \"twitter_avg_sentiment\": round(avg_compound, 4),\n",
    "#         \"twitter_bullish_ratio\": round(bullish_ratio, 4),\n",
    "#         \"twitter_bearish_ratio\": round(bearish_ratio, 4)\n",
    "#     }\n",
    "\n",
    "#     return full_twitter_df, twitter_sentiment_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8acf3d-5826-4127-b9de-cbe2953abebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_twitter_stock_sentiment(\n",
    "    ticker: str,\n",
    "    company_name: str = None,\n",
    "    max_results: int = 100,\n",
    "    retry_attempts: int = 2,\n",
    "    backoff_seconds: float = 5.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Uses snscrape to fetch tweets matching $TICKER, TICKER, or COMPANY_NAME.\n",
    "    Retries up to `retry_attempts` on ScraperException, backing off each time.\n",
    "    Returns (full_metrics_dict, sentiment_metrics_dict).\n",
    "    \"\"\"\n",
    "    # Build the query\n",
    "    clean = \"\".join(ch for ch in ticker if ch.isalnum()).upper()\n",
    "    parts = [f'\"${clean}\"', f'\"{clean}\"']\n",
    "    if company_name:\n",
    "        clean_nm = \"\".join(ch for ch in company_name if ch.isalnum() or ch.isspace())\n",
    "        parts.append(f'\"{clean_nm}\"')\n",
    "    query = \" OR \".join(parts) + \" lang:en\"\n",
    "\n",
    "    def zero_dict():\n",
    "        return (\n",
    "            {\n",
    "                \"ticker\":                ticker,\n",
    "                \"twitter_mentions\":      0,\n",
    "                \"twitter_bullish_count\": 0,\n",
    "                \"twitter_bearish_count\": 0,\n",
    "                \"twitter_avg_sentiment\": 0.0,\n",
    "                \"twitter_bullish_ratio\": 0.0,\n",
    "                \"twitter_bearish_ratio\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"ticker\":                ticker,\n",
    "                \"twitter_avg_sentiment\": 0.0,\n",
    "                \"twitter_bullish_ratio\": 0.0,\n",
    "                \"twitter_bearish_ratio\": 0.0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts <= retry_attempts:\n",
    "        try:\n",
    "            tweet_count = bull = bear = 0\n",
    "            total_compound = 0.0\n",
    "\n",
    "            for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "                if i >= max_results:\n",
    "                    break\n",
    "                text = tweet.content\n",
    "                low = text.lower()\n",
    "                is_bull = any(k in low for k in BULLISH_KEYWORDS)\n",
    "                is_bear = any(k in low for k in BEARISH_KEYWORDS)\n",
    "\n",
    "                tweet_count += 1\n",
    "                bull += int(is_bull)\n",
    "                bear += int(is_bear)\n",
    "                total_compound += sia.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "            if tweet_count == 0:\n",
    "                return zero_dict()\n",
    "\n",
    "            avg_compound = total_compound / tweet_count\n",
    "            bullish_ratio = bull / tweet_count\n",
    "            bearish_ratio = bear / tweet_count\n",
    "\n",
    "            full = {\n",
    "                \"ticker\":                ticker,\n",
    "                \"twitter_mentions\":      tweet_count,\n",
    "                \"twitter_bullish_count\": bull,\n",
    "                \"twitter_bearish_count\": bear,\n",
    "                \"twitter_avg_sentiment\": round(avg_compound, 4),\n",
    "                \"twitter_bullish_ratio\": round(bullish_ratio, 4),\n",
    "                \"twitter_bearish_ratio\": round(bearish_ratio, 4),\n",
    "            }\n",
    "            sentiment = {\n",
    "                \"ticker\":                ticker,\n",
    "                \"twitter_avg_sentiment\": round(avg_compound, 4),\n",
    "                \"twitter_bullish_ratio\": round(bullish_ratio, 4),\n",
    "                \"twitter_bearish_ratio\": round(bearish_ratio, 4),\n",
    "            }\n",
    "            return full, sentiment\n",
    "\n",
    "        except sb_exc.ScraperException as e:\n",
    "            attempts += 1\n",
    "            if attempts > retry_attempts:\n",
    "                print(f\"âŒ snscrape failed for {ticker} after {attempts} attempts: {e}\")\n",
    "                return zero_dict()\n",
    "            else:\n",
    "                print(f\"âš ï¸ snscrape error for {ticker}, retry {attempts}/{retry_attempts} after {backoff_seconds}s...\")\n",
    "                time.sleep(backoff_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51807442-ae5e-4280-8967-e0eda4fd6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_twitter(df):\n",
    "    start_time = time.perf_counter()\n",
    "    df_copy = df.copy()\n",
    "    records = []\n",
    "    full_records = []\n",
    "    for ticker, name in zip(df[\"ticker\"], df[\"name\"]):\n",
    "        full_metrics, sentiment_metrics = fetch_twitter_stock_sentiment(\n",
    "            ticker,\n",
    "            company_name=name,\n",
    "            max_results=10\n",
    "        )\n",
    "        records.append(sentiment_metrics)\n",
    "        full_records.append(full_metrics)\n",
    "\n",
    "    df_full = pd.DataFrame(full_records).set_index(\"ticker\")\n",
    "    df_full_twitter_metrics = df_copy.join(df_full, on=\"ticker\", how=\"left\")\n",
    "    \n",
    "    df_metrics = pd.DataFrame(records).set_index(\"ticker\")\n",
    "    df_twitter_sentiment_metrics = df.join(df_metrics, on=\"ticker\", how=\"left\")\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Results took: {end_time - start_time}\")\n",
    "    return df_full_twitter_metrics, df_twitter_sentiment_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2be1a2-01fb-4200-a9b3-347513a8a34f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start_time = time.perf_counter()\n",
    "\n",
    "# df_full_twitter, df_sm_sentiment = merge_twitter(df_equities)\n",
    "\n",
    "# end_time = time.perf_counter()\n",
    "# print(f\"Results took: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9188921-558e-4b7d-923e-275bb2e03a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>change_pct</th>\n",
       "      <th>reddit_avg_comment_sentiment</th>\n",
       "      <th>reddit_bullish_ratio</th>\n",
       "      <th>reddit_bearish_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCID</td>\n",
       "      <td>Lucid Group, Inc.</td>\n",
       "      <td>3.1150</td>\n",
       "      <td>36.026203</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMC</td>\n",
       "      <td>AMC Entertainment Holdings, Inc</td>\n",
       "      <td>3.5150</td>\n",
       "      <td>10.534593</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>Pepsico, Inc.</td>\n",
       "      <td>145.4956</td>\n",
       "      <td>7.495825</td>\n",
       "      <td>-0.0197</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO Inc.</td>\n",
       "      <td>4.4050</td>\n",
       "      <td>7.177617</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>0.2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIVN</td>\n",
       "      <td>Rivian Automotive, Inc.</td>\n",
       "      <td>12.9500</td>\n",
       "      <td>4.519770</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BBAI</td>\n",
       "      <td>BigBear.ai, Inc.</td>\n",
       "      <td>8.0350</td>\n",
       "      <td>12.851124</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QS</td>\n",
       "      <td>QuantumScape Corporation</td>\n",
       "      <td>13.3450</td>\n",
       "      <td>17.577091</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>Palantir Technologies Inc.</td>\n",
       "      <td>154.1050</td>\n",
       "      <td>2.117151</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>-7.856388</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "      <td>173.3550</td>\n",
       "      <td>1.158313</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TSM</td>\n",
       "      <td>Taiwan Semiconductor Manufactur</td>\n",
       "      <td>247.7550</td>\n",
       "      <td>4.291551</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>1271.9950</td>\n",
       "      <td>1.734365</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PGY</td>\n",
       "      <td>Pagaya Technologies Ltd.</td>\n",
       "      <td>29.6800</td>\n",
       "      <td>26.136843</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>512.2650</td>\n",
       "      <td>1.314232</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LLY</td>\n",
       "      <td>Eli Lilly and Company</td>\n",
       "      <td>761.8057</td>\n",
       "      <td>-3.544475</td>\n",
       "      <td>0.1119</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ELV</td>\n",
       "      <td>Elevance Health, Inc.</td>\n",
       "      <td>300.4300</td>\n",
       "      <td>-12.805107</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VLCN</td>\n",
       "      <td>Volcon, Inc.</td>\n",
       "      <td>21.9000</td>\n",
       "      <td>137.416380</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CRWV</td>\n",
       "      <td>CoreWeave, Inc.</td>\n",
       "      <td>133.9184</td>\n",
       "      <td>-6.376956</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QBTS</td>\n",
       "      <td>D-Wave Quantum Inc.</td>\n",
       "      <td>19.1450</td>\n",
       "      <td>13.217035</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BTOG</td>\n",
       "      <td>Bit Origin Limited</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>85.955380</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.3077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker                             name      price  change_pct  \\\n",
       "0    LCID                Lucid Group, Inc.     3.1150   36.026203   \n",
       "1     AMC  AMC Entertainment Holdings, Inc     3.5150   10.534593   \n",
       "2     PEP                    Pepsico, Inc.   145.4956    7.495825   \n",
       "3     NIO                         NIO Inc.     4.4050    7.177617   \n",
       "4    RIVN          Rivian Automotive, Inc.    12.9500    4.519770   \n",
       "5    BBAI                 BigBear.ai, Inc.     8.0350   12.851124   \n",
       "6      QS         QuantumScape Corporation    13.3450   17.577091   \n",
       "7    PLTR       Palantir Technologies Inc.   154.1050    2.117151   \n",
       "8     ABT              Abbott Laboratories   121.3900   -7.856388   \n",
       "9    NVDA               NVIDIA Corporation   173.3550    1.158313   \n",
       "10    TSM  Taiwan Semiconductor Manufactur   247.7550    4.291551   \n",
       "11   NFLX                    Netflix, Inc.  1271.9950    1.734365   \n",
       "12    PGY         Pagaya Technologies Ltd.    29.6800   26.136843   \n",
       "13   MSFT            Microsoft Corporation   512.2650    1.314232   \n",
       "14    LLY            Eli Lilly and Company   761.8057   -3.544475   \n",
       "15    ELV            Elevance Health, Inc.   300.4300  -12.805107   \n",
       "16   VLCN                     Volcon, Inc.    21.9000  137.416380   \n",
       "17   CRWV                  CoreWeave, Inc.   133.9184   -6.376956   \n",
       "18   QBTS              D-Wave Quantum Inc.    19.1450   13.217035   \n",
       "19   BTOG               Bit Origin Limited     0.6170   85.955380   \n",
       "\n",
       "    reddit_avg_comment_sentiment  reddit_bullish_ratio  reddit_bearish_ratio  \n",
       "0                         0.1925                0.3729                0.4746  \n",
       "1                         0.3486                0.2188                0.3125  \n",
       "2                        -0.0197                0.1626                0.2033  \n",
       "3                         0.0143                0.1509                0.2075  \n",
       "4                         0.0000                0.0000                0.0000  \n",
       "5                         0.2611                0.1942                0.3301  \n",
       "6                         0.1639                0.2133                0.2467  \n",
       "7                         0.1508                0.2231                0.2231  \n",
       "8                         0.0098                0.1840                0.2080  \n",
       "9                         0.1587                0.2255                0.2322  \n",
       "10                        0.0958                0.2701                0.2044  \n",
       "11                        0.0063                0.2654                0.2160  \n",
       "12                        0.0000                0.0000                0.0000  \n",
       "13                        0.1768                0.2280                0.2478  \n",
       "14                        0.1119                0.2455                0.2275  \n",
       "15                        0.0425                0.1802                0.1892  \n",
       "16                        0.0000                0.0000                0.0000  \n",
       "17                        0.1282                0.2285                0.2252  \n",
       "18                        0.0376                0.2245                0.1837  \n",
       "19                        0.1234                0.1282                0.3077  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_sentiment_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81263f67-25de-41fd-bc5c-c2fbbcd76b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_sm_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837756b2-61d3-42ee-a02d-af9255d7769e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ebbbeb-cc0a-457b-a51e-0fa458d3f4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
